{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Importamos nuestra librerías básicas\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Este paso es para que los resultados en vuestros notebooks sean iguales a lo de este\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Aprendizaje supervisado - SVM\n",
    "\n",
    "En este notebook volveremos a clasificar el MNIST, pero ahora utilizando el clasificador basado en Support Vector Machine o SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aqui importamos los datos que vamos a clasificar\n",
    "\n",
    "# Scikit-Learn ya incluye algunos datasets de ejemplo como el MNIST\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "\n",
    "# El dataset contiene 70.000 ejemplos de digitos escritos a mano\n",
    "# en blanco y negro. Cada digito esta representada por una imagen de 28x28 pixels.\n",
    "# Además el dataset incluye el \"target\" i.e. el numero asociado con cada imagen.\n",
    "\n",
    "# Otros datasets serían más rápidos de ejecutar, pero la ventaja de este es que,\n",
    "# debido a su complejidad, cuando empecemos a utilizar modelos más complejos (como \n",
    "# redes neuronales), se empezarán a ver las ventajas de estos modelos más complejos\n",
    "\n",
    "# Aqui cargamos nuestros ejemplos en X, el target en y. Nuestro objetivo con\n",
    "# Machine Learning es aprender la función f(X) que genera y.\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nuestro objetivo es que la función aprendida funcione no solamente con\n",
    "# el dataset de prueba, pero que también \"generalize\" bien para ejemplos\n",
    "# que no haya visto antes.\n",
    "\n",
    "# En esta sección separamos el dataset en 2 partes: el training set y test set\n",
    "X_train_o, X_test_o, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Antes de enviar los datos al modelo, hacemos una adaptación de los datos para normalizarlos\n",
    "# Por normalización en este contexto la idea es remover la media de cada \"feature\"\n",
    "# (i.e. centrar en zero) y dividir por la \"variance\", es decir hacer que los datos estén entre\n",
    "# 0 y 1.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_o)\n",
    "X_test = scaler.transform(X_test_o)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador utilizando Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 32s\n",
      "Wall time: 15min 38s\n",
      "Rendimiento en el dataset de training: 0.9853\n",
      "Wall time: 2min 35s\n",
      "Rendimiento en el dataset de pruebas: 0.9665\n"
     ]
    }
   ],
   "source": [
    "# El modelo SVC ...\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Creamos el modelo\n",
    "svc_clf = SVC(probability=True, random_state=42)\n",
    "\n",
    "# Hacemos fit del modelo al dato\n",
    "%time svc_clf.fit(X_train, y_train)\n",
    "\n",
    "# Medimos el rendimiento.\n",
    "%time train_score = svc_clf.score(X_train, y_train)\n",
    "print(\"Rendimiento en el dataset de training: %.4f\" % train_score)\n",
    "%time score = svc_clf.score(X_test, y_test)\n",
    "print(\"Rendimiento en el dataset de pruebas: %.4f\" % score)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
